{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import scipy \n",
    "from matplotlib import pylab\n",
    "import time\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data to training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>9.042040</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>6.561031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.247699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>9.169623</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>6.886532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652489</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.109016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>9.328212</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>6.188264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.075346</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.317171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.262680</td>\n",
       "      <td>9.164401</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>5.379897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.293419</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.849405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>9.565284</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>6.486161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.196444</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.429220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1    4.110874  9.042040            7            5       2003   \n",
       "1   2    3.044522  9.169623            6            8       1976   \n",
       "2   3    4.110874  9.328212            7            5       2001   \n",
       "3   4    4.262680  9.164401            7            5       1915   \n",
       "4   5    4.110874  9.565284            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF    ...      SaleType_New  \\\n",
       "0          2003    6.561031         0.0   5.017280    ...                 0   \n",
       "1          1976    6.886532         0.0   5.652489    ...                 0   \n",
       "2          2002    6.188264         0.0   6.075346    ...                 0   \n",
       "3          1970    5.379897         0.0   6.293419    ...                 0   \n",
       "4          2000    6.486161         0.0   6.196444    ...                 0   \n",
       "\n",
       "   SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n",
       "0             0            1                      0                      0   \n",
       "1             0            1                      0                      0   \n",
       "2             0            1                      0                      0   \n",
       "3             0            1                      1                      0   \n",
       "4             0            1                      0                      0   \n",
       "\n",
       "   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n",
       "0                     0                     0                     1   \n",
       "1                     0                     0                     1   \n",
       "2                     0                     0                     1   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   SaleCondition_Partial  SalePrice  \n",
       "0                      0  12.247699  \n",
       "1                      0  12.109016  \n",
       "2                      0  12.317171  \n",
       "3                      0  11.849405  \n",
       "4                      0  12.429220  \n",
       "\n",
       "[5 rows x 222 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    12.247699\n",
       "1    12.109016\n",
       "2    12.317171\n",
       "3    11.849405\n",
       "4    12.429220\n",
       "5    11.870607\n",
       "6    12.634606\n",
       "7    12.206078\n",
       "8    11.774528\n",
       "9    11.678448\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>9.042040</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>6.561031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.017280</td>\n",
       "      <td>6.753438</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>9.169623</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>6.886532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.652489</td>\n",
       "      <td>7.141245</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>9.328212</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>6.188264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.075346</td>\n",
       "      <td>6.825460</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.262680</td>\n",
       "      <td>9.164401</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>5.379897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.293419</td>\n",
       "      <td>6.629363</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>9.565284</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>6.486161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.196444</td>\n",
       "      <td>7.044033</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass   LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "0    4.110874  9.042040            7            5       2003          2003   \n",
       "1    3.044522  9.169623            6            8       1976          1976   \n",
       "2    4.110874  9.328212            7            5       2001          2002   \n",
       "3    4.262680  9.164401            7            5       1915          1970   \n",
       "4    4.110874  9.565284            8            5       2000          2000   \n",
       "\n",
       "   BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF          ...            \\\n",
       "0    6.561031         0.0   5.017280     6.753438          ...             \n",
       "1    6.886532         0.0   5.652489     7.141245          ...             \n",
       "2    6.188264         0.0   6.075346     6.825460          ...             \n",
       "3    5.379897         0.0   6.293419     6.629363          ...             \n",
       "4    6.486161         0.0   6.196444     7.044033          ...             \n",
       "\n",
       "   SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0               0             0             0            1   \n",
       "1               0             0             0            1   \n",
       "2               0             0             0            1   \n",
       "3               0             0             0            1   \n",
       "4               0             0             0            1   \n",
       "\n",
       "   SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                      0                      0                     0   \n",
       "1                      0                      0                     0   \n",
       "2                      0                      0                     0   \n",
       "3                      1                      0                     0   \n",
       "4                      0                      0                     0   \n",
       "\n",
       "   SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                     0                     1                      0  \n",
       "1                     0                     1                      0  \n",
       "2                     0                     1                      0  \n",
       "3                     0                     0                      0  \n",
       "4                     0                     1                      0  \n",
       "\n",
       "[5 rows x 220 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load the saved file to verify\n",
    "train_data = pd.read_pickle(\"./data/preprocessed/preprocessed_train.pkl\")\n",
    "display(train_data.head())\n",
    "\n",
    "#ave the identification number\n",
    "Id = train_data['Id']\n",
    "\n",
    "#save target varible\n",
    "target = train_data['SalePrice']\n",
    "display(train_data['SalePrice'].head(10))\n",
    "\n",
    "#remove target and ID, only features\n",
    "train_data.drop(labels=['SalePrice', 'Id'], axis=1, inplace=True)\n",
    "\n",
    "display(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978, 220)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(482, 220)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(978L,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(482L,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Split TRAINING SET into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split dataset where 33% is testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, target, test_size=0.33, random_state=42)\n",
    "\n",
    "## Verify the shape\n",
    "display(X_train.shape)\n",
    "display(X_test.shape)\n",
    "\n",
    "display(y_train.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Models\n",
    "\n",
    "In this section, I will try many machine learning models used to regression problems:\n",
    "Linear Regression (with Ridge and Lasso regularization); Support Vector Regression; Linear\n",
    "Support Vector Regression; Stochastic Gradient Descent; K Neighbors Regressor; Kernel Ridge\n",
    "Regression; Decision Tree Regressor;\n",
    "The method Cross Validation Score with score parameter defined as Root Mean Squared Error\n",
    "will be used to evaluate and compare the result of each individual learner. Just the bests model\n",
    "will be fine-tuned in the next step.\n",
    "\n",
    "\n",
    "> NOTE: [Skelarn.org](http://scikit-learn.org/stable/) was used as base to write comments about methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune Individual Models\n",
    "\n",
    "As the promising models were defined in the last step, now I will fine-tune the most promising\n",
    "models. The method to perform the fine-tune the hyper parameters will be Grid Search\n",
    "CV configured according to the project requisites. Thereby, each individual model will find the\n",
    "best parameters configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Croos-Valiation Score for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def rmse_CV(model, X, y):\n",
    "    print \"RMSE Metric\"\n",
    "    neg_msqe = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, verbose=0)\n",
    "    rmse= np.sqrt(-neg_msqe)\n",
    "    print \"Scores: \",rmse \n",
    "    print 'Mean:', rmse.mean()\n",
    "    print 'Standard Deviation: ', rmse.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Function: Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def GridSearch(reg, parameters, X, y):\n",
    "    \"\"\"\n",
    "    excecute grid search to determine the optimized parameters combination\n",
    "    \n",
    "    input\n",
    "    reg: the model; parameters: dict of parameters and options; X: dataframe, training features; y:pandas series, target feature;\n",
    "    \"\"\"\n",
    "    GSCV = GridSearchCV(reg, parameters, verbose=0, cv=5, n_jobs=-1)\n",
    "    best_model = GSCV.fit(X, y)\n",
    "    display(best_model)\n",
    "    display(best_model.best_params_)\n",
    "    \n",
    "    #return the configuration of best model\n",
    "    return best_model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual and Default Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.22812705 0.21240967 0.19650371]\n",
      "Mean: 0.21234680972875672\n",
      "Standard Deviation:  0.012910250261882738\n"
     ]
    }
   ],
   "source": [
    "#Import model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#Create Regressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "#Fit\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "rmse_CV(tree_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors Regressor\n",
    "\n",
    "Whrite about method: Regression based on k-nearest neighbors.\n",
    "The target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.2898332  0.27254986 0.24603219]\n",
      "Mean: 0.2694717493515401\n",
      "Standard Deviation:  0.018013663196502137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#Create the regressor\n",
    "neigh = KNeighborsRegressor()\n",
    "\n",
    "#Fit\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "#display(rmse(y_test, neigh.predict(X_test)))\n",
    "#Predict\n",
    "rmse_CV(neigh, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.26438393 0.39685316 0.39551933]\n",
      "Mean: 0.3522521412970557\n",
      "Standard Deviation:  0.06213459366926334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "#Create the regressor\n",
    "lin_svr = LinearSVR()\n",
    "\n",
    "#Fit\n",
    "lin_svr.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "#display(rmse(y_test, lin_svr.predict(X_test)))\n",
    "rmse_CV(lin_svr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epsilon Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.31528728 0.2957921  0.26767401]\n",
      "Mean: 0.2929177938961795\n",
      "Standard Deviation:  0.01954400345949258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "#Create Regressor\n",
    "svr = SVR()\n",
    "\n",
    "#Fit\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "#display(rmse(y_test, svr.predict(X_test)))\n",
    "rmse_CV(svr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regressor\n",
    "\n",
    "\"Kernel ridge regression (KRR) [M2012] combines Ridge Regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.\n",
    "\n",
    "The form of the model learned by KernelRidge is identical to support vector regression (SVR). However, different loss functions are used: KRR uses squared error loss while support vector regression uses \\epsilon-insensitive loss, both combined with l2 regularization. In contrast to SVR, fitting KernelRidge can be done in closed-form and is typically faster for medium-sized datasets.\" (Kernel ridge regression, Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.1315246  0.1347771  0.13511582]\n",
      "Mean: 0.13380583733776083\n",
      "Standard Deviation:  0.0016189972512706927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics.pairwise import chi2_kernel, laplacian_kernel\n",
    "#Create Regressor\n",
    "ker_rid = KernelRidge()\n",
    "\n",
    "#Fit\n",
    "ker_rid.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "#display(rmse(y_test, ker_rid.predict(X_test)))\n",
    "rmse_CV(ker_rid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Ordinary least squares Linear Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.17171291 0.14545081 0.17146583]\n",
      "Mean: 0.1628765145739622\n",
      "Standard Deviation:  0.012322249565294896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Create regressor\n",
    "lin_reg = LinearRegression(n_jobs=-1)\n",
    "\n",
    "#Fit\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "#display(rmse(y_test, ker_rid.predict(X_test)))\n",
    "rmse_CV(lin_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.29397053 0.28491712 0.25919599]\n",
      "Mean: 0.27936121223583466\n",
      "Standard Deviation:  0.01473020244739484\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#create \n",
    "lasso = Lasso()\n",
    "\n",
    "#Fit\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "#display(rmse(y_test, ker_rid.predict(X_test)))\n",
    "rmse_CV(lasso, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regressor\n",
    "\n",
    "\"ElasticNet is a linear regression model trained with L1 and L2 prior as regularizer. This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge. We control the convex combination of L1 and L2 using the l1_ratio parameter.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.28871097 0.28027105 0.25813338]\n",
      "Mean: 0.27570513216180476\n",
      "Standard Deviation:  0.012894002967574909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "#create regrossor\n",
    "elastic = ElasticNet()\n",
    "\n",
    "#Fit\n",
    "elastic.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "#display(rmse(y_test, ker_rid.predict(X_test)))\n",
    "rmse_CV(elastic, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [106.09450874 121.79677806  10.76018625]\n",
      "Mean: 79.55049101634147\n",
      "Standard Deviation:  49.06267989415548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#Create regressor\n",
    "MLP = MLPRegressor()\n",
    "\n",
    "#Fit\n",
    "MLP.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "#display(rmse(y_test, ker_rid.predict(X_test)))\n",
    "rmse_CV(MLP, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Process Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [11.99715014 11.9992195  12.05912791]\n",
      "Mean: 12.018499181960719\n",
      "Standard Deviation:  0.02874126575553559\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "#Create Regressor\n",
    "gpr = GaussianProcessRegressor()\n",
    "\n",
    "#Fit\n",
    "gpr.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "#display(rmse(y_test, ker_rid.predict(X_test)))\n",
    "rmse_CV(gpr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.12638924 0.16237844 0.12653831]\n",
      "Mean: 0.13843533085744136\n",
      "Standard Deviation:  0.01693044332030328\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#Create Regressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "\n",
    "#Fit\n",
    "GBR.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "#display(rmse(y_test, ker_rid.predict(X_test)))\n",
    "rmse_CV(GBR, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.17697204 0.18488708 0.15988305]\n",
      "Mean: 0.17391405724450704\n",
      "Standard Deviation:  0.010434362521077236\n"
     ]
    }
   ],
   "source": [
    "#Random Forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Create Regressor\n",
    "rand_F = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "#Fit\n",
    "rand_F.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "#display(rmse(y_test, ker_rid.predict(X_test)))\n",
    "rmse_CV(rand_F, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune Promissing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor\n",
    "\n",
    "Write about thi method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': ['auto', 'sqrt', 'log2', None], 'splitter': ['best', 'random'], 'criterion': ['mse', 'friedman_mse', 'mae']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse', 'max_features': 'auto', 'splitter': 'best'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Fine-Tune Time: -11.225000\n"
     ]
    }
   ],
   "source": [
    "#Import model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#Create Regressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "#Create Hyperparamter Search Space\n",
    "criterion = ['mse', 'friedman_mse', 'mae']\n",
    "splitter = ['best', 'random']\n",
    "max_depth = [2, 4, 6, 8, 10, 12] #== 'None' becuase nodes are expanded until \n",
    "#all leaves are pure or until all leaves contain less than min_samples_split samples\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "\n",
    "#Create hyperparameter options\n",
    "tree_hyper = dict(criterion=criterion, splitter=splitter, max_features=max_features)\n",
    "#print tree_hyper\n",
    "\n",
    "\n",
    "#Apply Grid Search To Determine the best model\n",
    "s_time = time.time()\n",
    "best_tree = GridSearch(tree_reg, tree_hyper, X_train, y_train)\n",
    "f_time = time.time()\n",
    "print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n",
    "#display(best_tree.get_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='friedman_mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "           splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print best_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.2038968  0.23366443 0.22982821]\n",
      "Mean: 0.22246314630207745\n",
      "Standard Deviation:  0.013221472127812437\n"
     ]
    }
   ],
   "source": [
    "score_tree = rmse_CV(best_tree, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors Regressor\n",
    "\n",
    "Whrite about method: Regression based on k-nearest neighbors.\n",
    "The target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "          weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'p': [1, 2], 'weights': ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'n_neighbors': [2, 4, 6, 8, 10, 12, 15, 20, 25]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'ball_tree', 'n_neighbors': 6, 'p': 1, 'weights': 'distance'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Fine-Tune Time: -32.861000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#Create the regressor\n",
    "neigh = KNeighborsRegressor()\n",
    "\n",
    "#Create Hyperparamter Search Space\n",
    "n_neighbors = [2, 4, 6, 8, 10, 12, 15, 20, 25]\n",
    "weights = ['uniform', 'distance']\n",
    "algorithm = ['ball_tree', 'kd_tree', 'brute']\n",
    "#algorithm = ['auto']\n",
    "p = [1, 2]\n",
    "\n",
    "#Create hyperparameter options\n",
    "neigh_param = dict(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm, p=p)\n",
    "#print tree_hyper\n",
    "\n",
    "\n",
    "#Apply Grid Search To Determine the best model\n",
    "s_time = time.time()\n",
    "best_neigh = GridSearch(neigh, neigh_param, X_train, y_train)\n",
    "f_time = time.time()\n",
    "print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n",
    "#display(best_tree.get_params)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print best_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 6, 'weights': 'distance', 'algorithm': 'ball_tree', 'p': 1}\n"
     ]
    }
   ],
   "source": [
    "#print best_neigh.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.25410762 0.24924477 0.20992898]\n",
      "Mean: 0.23776045523237385\n",
      "Standard Deviation:  0.01977970242938253\n"
     ]
    }
   ],
   "source": [
    "score_neigh = rmse_CV(best_neigh, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regressor\n",
    "\n",
    "\"Kernel ridge regression (KRR) [M2012] combines Ridge Regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.\n",
    "\n",
    "The form of the model learned by KernelRidge is identical to support vector regression (SVR). However, different loss functions are used: KRR uses squared error loss while support vector regression uses \\epsilon-insensitive loss, both combined with l2 regularization. In contrast to SVR, fitting KernelRidge can be done in closed-form and is typically faster for medium-sized datasets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
       "      kernel_params=None),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'kernel': ['laplacian', 'rbf', 'linear', 'poly', 'sigmoid'], 'gamma': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]), 'degree': [2, 3, 4, 5, 6, 7], 'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'degree': 2, 'gamma': 0.001, 'kernel': 'linear'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Fine-Tune Time: -924.851000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics.pairwise import chi2_kernel, laplacian_kernel\n",
    "#Create Regressor\n",
    "ker_rid = KernelRidge()\n",
    "\n",
    "#Create Hyperparamter Search Space\n",
    "alpha= [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0]\n",
    "kernel = ['laplacian', 'rbf', 'linear', 'poly', 'sigmoid']\n",
    "degree = [2,3,4,5,6,7]\n",
    "gamma = np.logspace(-3, 2, 6)\n",
    "\n",
    "#Create hyperparameter options\n",
    "ker_rid_param = dict(alpha=alpha, kernel=kernel, degree=degree, gamma=gamma)\n",
    "\n",
    "#Apply Grid Search To Determine the best model\n",
    "s_time = time.time()\n",
    "best_ker_rid = GridSearch(ker_rid, ker_rid_param, X_train, y_train)\n",
    "f_time = time.time()\n",
    "print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print best_ker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.1315246  0.1347771  0.13511582]\n",
      "Mean: 0.13380583733776083\n",
      "Standard Deviation:  0.0016189972512706927\n"
     ]
    }
   ],
   "source": [
    "score_ker_rid = rmse_CV(best_ker_rid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "whrite about model: \"The class SGDRegressor implements a plain stochastic gradient descent learning routine which supports different loss functions and penalties to fit linear regression models. **SGDRegressor is well suited for regression problems with a large number of training samples (> 10.000)**, for other problems we recommend Ridge, Lasso, or ElasticNet.\" (Stochastic Gradient Descent, Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=None, n_iter=None, penalty='l2',\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'penalty': ['l2', 'l1', 'elasticnet'], 'epsilon': [0, 0, 0.01, 0.1, 0.5, 1, 2, 4], 'learning_rate': ['constant', 'optimal', 'invscaling'], 'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001], 'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Fine-Tune Time: -284.812000\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "#Create a regressor\n",
    "#sgd = SGDRegressor()\n",
    "\n",
    "#Create Hyperparamter Search Space\n",
    "#loss = ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "#penalty = ['l2', 'l1', 'elasticnet']\n",
    "#alpha= [1.0, 0.1, 0.01, 0.001, 0.0001]\n",
    "#epsilon=[0, 0, 0.01, 0.1, 0.5, 1, 2, 4]\n",
    "#learning_rate = ['constant', 'optimal', 'invscaling']\n",
    "\n",
    "#Create hyperparameter options\n",
    "#sgd_param = dict(loss=loss, penalty=penalty, alpha=alpha, epsilon=epsilon, learning_rate=learning_rate)\n",
    "\n",
    "#Apply Grid Search To Determine the best model\n",
    "#s_time = time.time()\n",
    "#best_sgd = GridSearch(sgd, sgd_param, X_train, y_train)\n",
    "#f_time = time.time()\n",
    "#print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n",
    "\n",
    "\n",
    "#sgd_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.02460181 0.02275077 0.02262368 0.02334927 0.02355519 0.02407193\n",
      " 0.02302386 0.02109088 0.02132617 0.02126972]\n",
      "Mean: 0.02276632855466759\n",
      "Standard Deviation:  0.001150810555570769\n"
     ]
    }
   ],
   "source": [
    "#score_sgd = rmse_CV(best_sgd, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Ordinary least squares Linear Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Create regressor\n",
    "lin_reg = LinearRegression(n_jobs=-1)\n",
    "\n",
    "#Create Hyperparamter Search Space\n",
    "\n",
    "#There isn't parameters to tune\n",
    "\n",
    "best_lin_reg = lin_reg\n",
    "\n",
    "#lin_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.17171291 0.14545081 0.17146583]\n",
      "Mean: 0.1628765145739622\n",
      "Standard Deviation:  0.012322249565294896\n"
     ]
    }
   ],
   "source": [
    "score_lin_reg = rmse_CV(best_lin_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'normalize': [False], 'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0], 'selection': ['cyclic', 'random'], 'fit_intercept': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001,\n",
       " 'fit_intercept': True,\n",
       " 'normalize': False,\n",
       " 'selection': 'random'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Fine-Tune Time: -11.879000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#create \n",
    "lasso = Lasso()\n",
    "\n",
    "#Create Hyperparamter Search Space\n",
    "alpha= [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0]\n",
    "fit_intercept = [True, False]\n",
    "normalize=[False]\n",
    "#precompute=[auto]\n",
    "selection=['cyclic', 'random']\n",
    "\n",
    "#Create hyperparameter options\n",
    "lasso_param = dict(alpha=alpha, fit_intercept=fit_intercept, normalize=normalize, selection=selection)\n",
    "\n",
    "#Apply Grid Search To Determine the best model\n",
    "s_time = time.time()\n",
    "best_lasso= GridSearch(lasso, lasso_param, X_train, y_train)\n",
    "f_time = time.time()\n",
    "print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.15035719 0.13107585 0.13499215]\n",
      "Mean: 0.13880839390878633\n",
      "Standard Deviation:  0.00832127350957245\n"
     ]
    }
   ],
   "source": [
    "score_lasso = rmse_CV(best_lasso, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regressor\n",
    "\n",
    "\"ElasticNet is a linear regression model trained with L1 and L2 prior as regularizer. This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge. We control the convex combination of L1 and L2 using the l1_ratio parameter.\" (Scikit-Learn Documentation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'normalize': [False], 'l1_ratio': [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0], 'selection': ['cyclic', 'random'], 'fit_intercept': [True, False], 'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001,\n",
       " 'fit_intercept': True,\n",
       " 'l1_ratio': 1.0,\n",
       " 'normalize': False,\n",
       " 'selection': 'random'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Fine-Tune Time: -82.903000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "#create regrossor\n",
    "elastic = ElasticNet()\n",
    "\n",
    "##Create Hyperparamter Search Space\n",
    "alpha= [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0]\n",
    "l1_ratio = [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0]\n",
    "fit_intercept = [True, False]\n",
    "normalize=[False]\n",
    "#precompute=['auto']\n",
    "selection=['cyclic', 'random']\n",
    "\n",
    "#Create hyperparameter options\n",
    "elastic_param = dict(alpha=alpha, fit_intercept=fit_intercept, l1_ratio=l1_ratio, normalize=normalize, selection=selection)\n",
    "\n",
    "\n",
    "#Apply Grid Search To Determine the best model\n",
    "s_time = time.time()\n",
    "best_elastic= GridSearch(elastic, elastic_param, X_train, y_train)\n",
    "f_time = time.time()\n",
    "print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n",
    "\n",
    "\n",
    "#elast_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.15045421 0.13108303 0.13507172]\n",
      "Mean: 0.1388696531754481\n",
      "Standard Deviation:  0.008351803659718092\n"
     ]
    }
   ],
   "source": [
    "score_lasso = rmse_CV(best_elastic, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Regressor\n",
    "\n",
    "\"The Perceptron is another simple algorithm suitable for large scale learning. By default:\n",
    "\n",
    "* It does not require a learning rate.\n",
    "* It is not regularized (penalized).\n",
    "* It updates its model only on mistakes.\n",
    "\n",
    "The last characteristic implies that the Perceptron is slightly faster to train than SGD with the hinge loss and that the resulting models are sparser.\" ([W3cubDocs](http://docs.w3cub.com/scikit_learn/modules/linear_model/))\n",
    "\n",
    "> **NOTE:** This optmization failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\runpy.py in _run_code(code=<code object <module> at 000000000253CAB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\Use...s\\py2\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 000000000253CAB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\Use...s\\py2\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 3, 12, 20, 12, 5, 262000, tzinfo=tzutc()), u'msg_id': u'2a4e9c3054294274abae1e8573d61c47', u'msg_type': u'execute_request', u'session': u'80766c297ee54be9827299854bda0864', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'2a4e9c3054294274abae1e8573d61c47', 'msg_type': u'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['80766c297ee54be9827299854bda0864']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 3, 12, 20, 12, 5, 262000, tzinfo=tzutc()), u'msg_id': u'2a4e9c3054294274abae1e8573d61c47', u'msg_type': u'execute_request', u'session': u'80766c297ee54be9827299854bda0864', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'2a4e9c3054294274abae1e8573d61c47', 'msg_type': u'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['80766c297ee54be9827299854bda0864'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 3, 12, 20, 12, 5, 262000, tzinfo=tzutc()), u'msg_id': u'2a4e9c3054294274abae1e8573d61c47', u'msg_type': u'execute_request', u'session': u'80766c297ee54be9827299854bda0864', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'2a4e9c3054294274abae1e8573d61c47', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Print object>], cell_name='<ipython-input-24-585cc111cdd8>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at b608160, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 000000000B330130, file \"<ipython-input-24-585cc111cdd8>\", line 19>\n        result = <ExecutionResult object at b608160, execution_co..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 000000000B330130, file \"<ipython-input-24-585cc111cdd8>\", line 19>, result=<ExecutionResult object at b608160, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 000000000B330130, file \"<ipython-input-24-585cc111cdd8>\", line 19>\n        self.user_global_ns = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'GridSearch': <function GridSearch>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"# Import libraries necessary for this project\\...books\\nget_ipython().magic(u'matplotlib inline')\", u'#Load the saved file to verify\\ntrain_data = p...processed_train_target.pkl\")\\n#display(y.head())', u'#Load the saved file to verify\\ntrain_data = p...())\\ndisplay(train_data[\\'SalePrice\\'].head(10))', u\"#train samples\\ny_train = train_data['SalePric...st = test_data.drop(columns='SalePrice', axis=1)\", u'#Load the saved file to verify\\ntest_data = pd...eprocessed_test_target.pkl\")\\n#display(y.head())', u'## Verify the shape\\ndisplay(train_data.shape)...in_PCA_data.shape)\\ndisplay(test_PCA_data.shape)', u\"#train samples\\ny_train = train_data['SalePric...st = test_data.drop(columns='SalePrice', axis=1)\", u'from sklearn.model_selection import cross_val_...ndard Deviation: \\', rmse.std()\\n    return rmse', u'from sklearn.metrics import mean_squared_error...   return np.sqrt(mean_squared_error(y, y_pred))', u'from sklearn.model_selection import Randomized...\\n    display(best_model)\\n    return best_model', u'from sklearn.model_selection import GridSearch...\\n    display(best_model)\\n    return best_model', u'#Import model\\nfrom sklearn.tree import Decisi...RandomSearch(tree_reg, tree_hyper, X_PCA, y_PCA)', u'score_tree = rmse_CV(best_tree, X_train, y_train)', u'from sklearn.neighbors import KNeighborsRegres...RandomSearch(tree_reg, tree_hyper, X_PCA, y_PCA)', u'score_neigh = rmse_CV(best_neigh, X_train, y_train)', u'#import\\nfrom sklearn.svm import LinearSVR\\n\\n...should scale better to large numbers of samples.', u'score_lin_svr = rmse_CV(best_lin_svr, X_train, y_train)', u\"from sklearn.linear_model import LinearRegress...e\\n\\nbest_lin_reg = lin_reg\\n\\n#lin_reg.fit(X,y)\", u'score_lin_reg = rmse_CV(best_lin_reg, X_train, y_train)', ...], 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, 'LinearSVR': <class 'sklearn.svm.classes.LinearSVR'>, ...}\n        self.user_ns = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'GridSearch': <function GridSearch>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"# Import libraries necessary for this project\\...books\\nget_ipython().magic(u'matplotlib inline')\", u'#Load the saved file to verify\\ntrain_data = p...processed_train_target.pkl\")\\n#display(y.head())', u'#Load the saved file to verify\\ntrain_data = p...())\\ndisplay(train_data[\\'SalePrice\\'].head(10))', u\"#train samples\\ny_train = train_data['SalePric...st = test_data.drop(columns='SalePrice', axis=1)\", u'#Load the saved file to verify\\ntest_data = pd...eprocessed_test_target.pkl\")\\n#display(y.head())', u'## Verify the shape\\ndisplay(train_data.shape)...in_PCA_data.shape)\\ndisplay(test_PCA_data.shape)', u\"#train samples\\ny_train = train_data['SalePric...st = test_data.drop(columns='SalePrice', axis=1)\", u'from sklearn.model_selection import cross_val_...ndard Deviation: \\', rmse.std()\\n    return rmse', u'from sklearn.metrics import mean_squared_error...   return np.sqrt(mean_squared_error(y, y_pred))', u'from sklearn.model_selection import Randomized...\\n    display(best_model)\\n    return best_model', u'from sklearn.model_selection import GridSearch...\\n    display(best_model)\\n    return best_model', u'#Import model\\nfrom sklearn.tree import Decisi...RandomSearch(tree_reg, tree_hyper, X_PCA, y_PCA)', u'score_tree = rmse_CV(best_tree, X_train, y_train)', u'from sklearn.neighbors import KNeighborsRegres...RandomSearch(tree_reg, tree_hyper, X_PCA, y_PCA)', u'score_neigh = rmse_CV(best_neigh, X_train, y_train)', u'#import\\nfrom sklearn.svm import LinearSVR\\n\\n...should scale better to large numbers of samples.', u'score_lin_svr = rmse_CV(best_lin_svr, X_train, y_train)', u\"from sklearn.linear_model import LinearRegress...e\\n\\nbest_lin_reg = lin_reg\\n\\n#lin_reg.fit(X,y)\", u'score_lin_reg = rmse_CV(best_lin_reg, X_train, y_train)', ...], 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, 'LinearSVR': <class 'sklearn.svm.classes.LinearSVR'>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\User\\Desktop\\Machine Learning ND\\Capstone Project\\Capstone Project\\<ipython-input-24-585cc111cdd8> in <module>()\n     14 percep_param = dict(penalty=penalty, alpha=alpha, n_jobs=n_jobs, class_weight=class_weight)\n     15 \n     16 \n     17 #Apply Grid Search To Determine the best model\n     18 s_time = time.time()\n---> 19 best_percep= GridSearch(percep, percep_param, X_train, y_train)\n     20 f_time = time.time()\n     21 print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n     22 \n     23 \n\n...........................................................................\nC:\\Users\\User\\Desktop\\Machine Learning ND\\Capstone Project\\Capstone Project\\<ipython-input-11-9ad707ef2880> in GridSearch(reg=Perceptron(alpha=0.0001, class_weight=None, eta0...ffle=True, tol=None, verbose=0, warm_start=False), parameters={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0], 'class_weight': ['balanced', None], 'n_jobs': [-1], 'penalty': ['l1', 'l2', 'elasticnet']}, X=      Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1897 rows x 287 columns], y=2259    0.206746\n1615    0.204613\n1241    0.1819...940\nName: SalePrice, Length: 1897, dtype: float64)\n      1 from sklearn.model_selection import GridSearchCV\n      2 \n      3 def GridSearch(reg, parameters, X, y):\n      4     GSCV = GridSearchCV(reg, parameters, verbose=0, cv=5, n_jobs=-1)\n----> 5     best_model = GSCV.fit(X, y)\n      6     display(best_model)\n      7     return best_model\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=      Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1897 rows x 287 columns], y=2259    0.206746\n1615    0.204613\n1241    0.1819...940\nName: SalePrice, Length: 1897, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method KFold.split of KFold(n_splits=5, random_state=None, shuffle=False)>\n        X =       Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1897 rows x 287 columns]\n        y = 2259    0.206746\n1615    0.204613\n1241    0.1819...940\nName: SalePrice, Length: 1897, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Mar 12 18:50:32 2018\nPID: 8272        Python 2.7.14: C:\\Users\\User\\Anaconda3\\envs\\py2\\python.exe\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False),       Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1897 rows x 287 columns], 2259    0.206746\n1615    0.204613\n1241    0.1819...940\nName: SalePrice, Length: 1897, dtype: float64, {'score': <function _passthrough_scorer>}, array([ 380,  381,  382, ..., 1894, 1895, 1896]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 372, 373, 374, 375, 376,\n       377, 378, 379]), 0, {'alpha': 1.0, 'class_weight': 'balanced', 'n_jobs': -1, 'penalty': 'l1'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False),       Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1897 rows x 287 columns], 2259    0.206746\n1615    0.204613\n1241    0.1819...940\nName: SalePrice, Length: 1897, dtype: float64, {'score': <function _passthrough_scorer>}, array([ 380,  381,  382, ..., 1894, 1895, 1896]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 372, 373, 374, 375, 376,\n       377, 378, 379]), 0, {'alpha': 1.0, 'class_weight': 'balanced', 'n_jobs': -1, 'penalty': 'l1'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False), X=      Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1897 rows x 287 columns], y=2259    0.206746\n1615    0.204613\n1241    0.1819...940\nName: SalePrice, Length: 1897, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([ 380,  381,  382, ..., 1894, 1895, 1896]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 372, 373, 374, 375, 376,\n       377, 378, 379]), verbose=0, parameters={'alpha': 1.0, 'class_weight': 'balanced', 'n_jobs': -1, 'penalty': 'l1'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Perceptron.fit of Perceptron(alpha...fle=True, tol=None, verbose=0, warm_start=False)>\n        X_train =       Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1517 rows x 287 columns]\n        y_train = 697     0.134334\n2446    0.299922\n348     0.1640...940\nName: SalePrice, Length: 1517, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in fit(self=Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False), X=      Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1517 rows x 287 columns], y=697     0.134334\n2446    0.299922\n348     0.1640...940\nName: SalePrice, Length: 1517, dtype: float64, coef_init=None, intercept_init=None, sample_weight=None)\n    581         self : returns an instance of self.\n    582         \"\"\"\n    583         return self._fit(X, y, alpha=self.alpha, C=1.0,\n    584                          loss=self.loss, learning_rate=self.learning_rate,\n    585                          coef_init=coef_init, intercept_init=intercept_init,\n--> 586                          sample_weight=sample_weight)\n        sample_weight = None\n    587 \n    588 \n    589 class SGDClassifier(BaseSGDClassifier):\n    590     \"\"\"Linear classifiers (SVM, logistic regression, a.o.) with SGD training.\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in _fit(self=Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False), X=array([[0.02124481, 0.23489509, 0.4624497 , ...,....., 0.        , 0.        ,\n        0.        ]]), y=array([0.13433433, 0.29992203, 0.1640804 , ..., 0.19548016, 0.16127689,\n       0.13893983]), alpha=1.0, C=1.0, loss='perceptron', learning_rate='constant', coef_init=None, intercept_init=None, sample_weight=None)\n    439 \n    440         # Clear iteration count for multiple call to fit.\n    441         self.t_ = 1.0\n    442 \n    443         self._partial_fit(X, y, alpha, C, loss, learning_rate, self._max_iter,\n--> 444                           classes, sample_weight, coef_init, intercept_init)\n        classes = array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819])\n        sample_weight = None\n        coef_init = None\n        intercept_init = None\n    445 \n    446         if (self._tol is not None and self._tol > -np.inf\n    447                 and self.n_iter_ == self._max_iter):\n    448             warnings.warn(\"Maximum number of iteration reached before \"\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in _partial_fit(self=Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False), X=array([[0.02124481, 0.23489509, 0.4624497 , ...,....., 0.        , 0.        ,\n        0.        ]]), y=array([0.13433433, 0.29992203, 0.1640804 , ..., 0.19548016, 0.16127689,\n       0.13893983]), alpha=1.0, C=1.0, loss='perceptron', learning_rate='constant', max_iter=5, classes=array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819]), sample_weight=None, coef_init=None, intercept_init=None)\n    370                      coef_init, intercept_init):\n    371         X, y = check_X_y(X, y, 'csr', dtype=np.float64, order=\"C\")\n    372 \n    373         n_samples, n_features = X.shape\n    374 \n--> 375         _check_partial_fit_first_call(self, classes)\n        self = Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False)\n        classes = array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819])\n    376 \n    377         n_classes = self.classes_.shape[0]\n    378 \n    379         # Allocate datastructures from input arguments\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\utils\\multiclass.py in _check_partial_fit_first_call(clf=Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False), classes=array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819]))\n    316                     \"`classes=%r` is not the same as on last call \"\n    317                     \"to partial_fit, was: %r\" % (classes, clf.classes_))\n    318 \n    319         else:\n    320             # This is the first call to partial_fit\n--> 321             clf.classes_ = unique_labels(classes)\n        clf.classes_ = undefined\n        classes = array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819])\n    322             return True\n    323 \n    324     # classes is None and clf.classes_ has already previously been set:\n    325     # nothing to do\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\utils\\multiclass.py in unique_labels(*ys=(array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819]),))\n     92                          \"different numbers of labels\")\n     93 \n     94     # Get the unique set of labels\n     95     _unique_labels = _FN_UNIQUE_LABELS.get(label_type, None)\n     96     if not _unique_labels:\n---> 97         raise ValueError(\"Unknown label type: %s\" % repr(ys))\n        ys = (array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819]),)\n     98 \n     99     ys_labels = set(chain.from_iterable(_unique_labels(y) for y in ys))\n    100 \n    101     # Check that we don't mix string type with number type\n\nValueError: Unknown label type: (array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819]),)\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-585cc111cdd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#Apply Grid Search To Determine the best model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0ms_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mbest_percep\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mGridSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpercep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpercep_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mf_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Training and Fine-Tune Time: {:3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-9ad707ef2880>\u001b[0m in \u001b[0;36mGridSearch\u001b[1;34m(reg, parameters, X, y)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mGridSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mGSCV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGSCV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\runpy.py in _run_code(code=<code object <module> at 000000000253CAB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\Use...s\\py2\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 000000000253CAB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\Use...s\\py2\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 3, 12, 20, 12, 5, 262000, tzinfo=tzutc()), u'msg_id': u'2a4e9c3054294274abae1e8573d61c47', u'msg_type': u'execute_request', u'session': u'80766c297ee54be9827299854bda0864', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'2a4e9c3054294274abae1e8573d61c47', 'msg_type': u'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['80766c297ee54be9827299854bda0864']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 3, 12, 20, 12, 5, 262000, tzinfo=tzutc()), u'msg_id': u'2a4e9c3054294274abae1e8573d61c47', u'msg_type': u'execute_request', u'session': u'80766c297ee54be9827299854bda0864', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'2a4e9c3054294274abae1e8573d61c47', 'msg_type': u'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['80766c297ee54be9827299854bda0864'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 3, 12, 20, 12, 5, 262000, tzinfo=tzutc()), u'msg_id': u'2a4e9c3054294274abae1e8573d61c47', u'msg_type': u'execute_request', u'session': u'80766c297ee54be9827299854bda0864', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'2a4e9c3054294274abae1e8573d61c47', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'from sklearn.linear_model import Perceptron\\n\\...mat((s_time - f_time))\\n\\n\\n\\n\\n#percep.fit(X,y)', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Print object>], cell_name='<ipython-input-24-585cc111cdd8>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at b608160, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 000000000B330130, file \"<ipython-input-24-585cc111cdd8>\", line 19>\n        result = <ExecutionResult object at b608160, execution_co..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 000000000B330130, file \"<ipython-input-24-585cc111cdd8>\", line 19>, result=<ExecutionResult object at b608160, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 000000000B330130, file \"<ipython-input-24-585cc111cdd8>\", line 19>\n        self.user_global_ns = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'GridSearch': <function GridSearch>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"# Import libraries necessary for this project\\...books\\nget_ipython().magic(u'matplotlib inline')\", u'#Load the saved file to verify\\ntrain_data = p...processed_train_target.pkl\")\\n#display(y.head())', u'#Load the saved file to verify\\ntrain_data = p...())\\ndisplay(train_data[\\'SalePrice\\'].head(10))', u\"#train samples\\ny_train = train_data['SalePric...st = test_data.drop(columns='SalePrice', axis=1)\", u'#Load the saved file to verify\\ntest_data = pd...eprocessed_test_target.pkl\")\\n#display(y.head())', u'## Verify the shape\\ndisplay(train_data.shape)...in_PCA_data.shape)\\ndisplay(test_PCA_data.shape)', u\"#train samples\\ny_train = train_data['SalePric...st = test_data.drop(columns='SalePrice', axis=1)\", u'from sklearn.model_selection import cross_val_...ndard Deviation: \\', rmse.std()\\n    return rmse', u'from sklearn.metrics import mean_squared_error...   return np.sqrt(mean_squared_error(y, y_pred))', u'from sklearn.model_selection import Randomized...\\n    display(best_model)\\n    return best_model', u'from sklearn.model_selection import GridSearch...\\n    display(best_model)\\n    return best_model', u'#Import model\\nfrom sklearn.tree import Decisi...RandomSearch(tree_reg, tree_hyper, X_PCA, y_PCA)', u'score_tree = rmse_CV(best_tree, X_train, y_train)', u'from sklearn.neighbors import KNeighborsRegres...RandomSearch(tree_reg, tree_hyper, X_PCA, y_PCA)', u'score_neigh = rmse_CV(best_neigh, X_train, y_train)', u'#import\\nfrom sklearn.svm import LinearSVR\\n\\n...should scale better to large numbers of samples.', u'score_lin_svr = rmse_CV(best_lin_svr, X_train, y_train)', u\"from sklearn.linear_model import LinearRegress...e\\n\\nbest_lin_reg = lin_reg\\n\\n#lin_reg.fit(X,y)\", u'score_lin_reg = rmse_CV(best_lin_reg, X_train, y_train)', ...], 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, 'LinearSVR': <class 'sklearn.svm.classes.LinearSVR'>, ...}\n        self.user_ns = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'DecisionTreeRegressor': <class 'sklearn.tree.tree.DecisionTreeRegressor'>, 'ElasticNet': <class 'sklearn.linear_model.coordinate_descent.ElasticNet'>, 'GridSearch': <function GridSearch>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"# Import libraries necessary for this project\\...books\\nget_ipython().magic(u'matplotlib inline')\", u'#Load the saved file to verify\\ntrain_data = p...processed_train_target.pkl\")\\n#display(y.head())', u'#Load the saved file to verify\\ntrain_data = p...())\\ndisplay(train_data[\\'SalePrice\\'].head(10))', u\"#train samples\\ny_train = train_data['SalePric...st = test_data.drop(columns='SalePrice', axis=1)\", u'#Load the saved file to verify\\ntest_data = pd...eprocessed_test_target.pkl\")\\n#display(y.head())', u'## Verify the shape\\ndisplay(train_data.shape)...in_PCA_data.shape)\\ndisplay(test_PCA_data.shape)', u\"#train samples\\ny_train = train_data['SalePric...st = test_data.drop(columns='SalePrice', axis=1)\", u'from sklearn.model_selection import cross_val_...ndard Deviation: \\', rmse.std()\\n    return rmse', u'from sklearn.metrics import mean_squared_error...   return np.sqrt(mean_squared_error(y, y_pred))', u'from sklearn.model_selection import Randomized...\\n    display(best_model)\\n    return best_model', u'from sklearn.model_selection import GridSearch...\\n    display(best_model)\\n    return best_model', u'#Import model\\nfrom sklearn.tree import Decisi...RandomSearch(tree_reg, tree_hyper, X_PCA, y_PCA)', u'score_tree = rmse_CV(best_tree, X_train, y_train)', u'from sklearn.neighbors import KNeighborsRegres...RandomSearch(tree_reg, tree_hyper, X_PCA, y_PCA)', u'score_neigh = rmse_CV(best_neigh, X_train, y_train)', u'#import\\nfrom sklearn.svm import LinearSVR\\n\\n...should scale better to large numbers of samples.', u'score_lin_svr = rmse_CV(best_lin_svr, X_train, y_train)', u\"from sklearn.linear_model import LinearRegress...e\\n\\nbest_lin_reg = lin_reg\\n\\n#lin_reg.fit(X,y)\", u'score_lin_reg = rmse_CV(best_lin_reg, X_train, y_train)', ...], 'KNeighborsRegressor': <class 'sklearn.neighbors.regression.KNeighborsRegressor'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearRegression': <class 'sklearn.linear_model.base.LinearRegression'>, 'LinearSVR': <class 'sklearn.svm.classes.LinearSVR'>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\User\\Desktop\\Machine Learning ND\\Capstone Project\\Capstone Project\\<ipython-input-24-585cc111cdd8> in <module>()\n     14 percep_param = dict(penalty=penalty, alpha=alpha, n_jobs=n_jobs, class_weight=class_weight)\n     15 \n     16 \n     17 #Apply Grid Search To Determine the best model\n     18 s_time = time.time()\n---> 19 best_percep= GridSearch(percep, percep_param, X_train, y_train)\n     20 f_time = time.time()\n     21 print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n     22 \n     23 \n\n...........................................................................\nC:\\Users\\User\\Desktop\\Machine Learning ND\\Capstone Project\\Capstone Project\\<ipython-input-11-9ad707ef2880> in GridSearch(reg=Perceptron(alpha=0.0001, class_weight=None, eta0...ffle=True, tol=None, verbose=0, warm_start=False), parameters={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0], 'class_weight': ['balanced', None], 'n_jobs': [-1], 'penalty': ['l1', 'l2', 'elasticnet']}, X=      Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1897 rows x 287 columns], y=2259    0.206746\n1615    0.204613\n1241    0.1819...940\nName: SalePrice, Length: 1897, dtype: float64)\n      1 from sklearn.model_selection import GridSearchCV\n      2 \n      3 def GridSearch(reg, parameters, X, y):\n      4     GSCV = GridSearchCV(reg, parameters, verbose=0, cv=5, n_jobs=-1)\n----> 5     best_model = GSCV.fit(X, y)\n      6     display(best_model)\n      7     return best_model\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=      Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1897 rows x 287 columns], y=2259    0.206746\n1615    0.204613\n1241    0.1819...940\nName: SalePrice, Length: 1897, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method KFold.split of KFold(n_splits=5, random_state=None, shuffle=False)>\n        X =       Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1897 rows x 287 columns]\n        y = 2259    0.206746\n1615    0.204613\n1241    0.1819...940\nName: SalePrice, Length: 1897, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Mar 12 18:50:32 2018\nPID: 8272        Python 2.7.14: C:\\Users\\User\\Anaconda3\\envs\\py2\\python.exe\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False),       Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1897 rows x 287 columns], 2259    0.206746\n1615    0.204613\n1241    0.1819...940\nName: SalePrice, Length: 1897, dtype: float64, {'score': <function _passthrough_scorer>}, array([ 380,  381,  382, ..., 1894, 1895, 1896]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 372, 373, 374, 375, 376,\n       377, 378, 379]), 0, {'alpha': 1.0, 'class_weight': 'balanced', 'n_jobs': -1, 'penalty': 'l1'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False),       Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1897 rows x 287 columns], 2259    0.206746\n1615    0.204613\n1241    0.1819...940\nName: SalePrice, Length: 1897, dtype: float64, {'score': <function _passthrough_scorer>}, array([ 380,  381,  382, ..., 1894, 1895, 1896]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 372, 373, 374, 375, 376,\n       377, 378, 379]), 0, {'alpha': 1.0, 'class_weight': 'balanced', 'n_jobs': -1, 'penalty': 'l1'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False), X=      Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1897 rows x 287 columns], y=2259    0.206746\n1615    0.204613\n1241    0.1819...940\nName: SalePrice, Length: 1897, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([ 380,  381,  382, ..., 1894, 1895, 1896]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 372, 373, 374, 375, 376,\n       377, 378, 379]), verbose=0, parameters={'alpha': 1.0, 'class_weight': 'balanced', 'n_jobs': -1, 'penalty': 'l1'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Perceptron.fit of Perceptron(alpha...fle=True, tol=None, verbose=0, warm_start=False)>\n        X_train =       Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1517 rows x 287 columns]\n        y_train = 697     0.134334\n2446    0.299922\n348     0.1640...940\nName: SalePrice, Length: 1517, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in fit(self=Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False), X=      Lot Area  Overall Qual  Overall Cond  Year... 0                 0  \n\n[1517 rows x 287 columns], y=697     0.134334\n2446    0.299922\n348     0.1640...940\nName: SalePrice, Length: 1517, dtype: float64, coef_init=None, intercept_init=None, sample_weight=None)\n    581         self : returns an instance of self.\n    582         \"\"\"\n    583         return self._fit(X, y, alpha=self.alpha, C=1.0,\n    584                          loss=self.loss, learning_rate=self.learning_rate,\n    585                          coef_init=coef_init, intercept_init=intercept_init,\n--> 586                          sample_weight=sample_weight)\n        sample_weight = None\n    587 \n    588 \n    589 class SGDClassifier(BaseSGDClassifier):\n    590     \"\"\"Linear classifiers (SVM, logistic regression, a.o.) with SGD training.\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in _fit(self=Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False), X=array([[0.02124481, 0.23489509, 0.4624497 , ...,....., 0.        , 0.        ,\n        0.        ]]), y=array([0.13433433, 0.29992203, 0.1640804 , ..., 0.19548016, 0.16127689,\n       0.13893983]), alpha=1.0, C=1.0, loss='perceptron', learning_rate='constant', coef_init=None, intercept_init=None, sample_weight=None)\n    439 \n    440         # Clear iteration count for multiple call to fit.\n    441         self.t_ = 1.0\n    442 \n    443         self._partial_fit(X, y, alpha, C, loss, learning_rate, self._max_iter,\n--> 444                           classes, sample_weight, coef_init, intercept_init)\n        classes = array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819])\n        sample_weight = None\n        coef_init = None\n        intercept_init = None\n    445 \n    446         if (self._tol is not None and self._tol > -np.inf\n    447                 and self.n_iter_ == self._max_iter):\n    448             warnings.warn(\"Maximum number of iteration reached before \"\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in _partial_fit(self=Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False), X=array([[0.02124481, 0.23489509, 0.4624497 , ...,....., 0.        , 0.        ,\n        0.        ]]), y=array([0.13433433, 0.29992203, 0.1640804 , ..., 0.19548016, 0.16127689,\n       0.13893983]), alpha=1.0, C=1.0, loss='perceptron', learning_rate='constant', max_iter=5, classes=array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819]), sample_weight=None, coef_init=None, intercept_init=None)\n    370                      coef_init, intercept_init):\n    371         X, y = check_X_y(X, y, 'csr', dtype=np.float64, order=\"C\")\n    372 \n    373         n_samples, n_features = X.shape\n    374 \n--> 375         _check_partial_fit_first_call(self, classes)\n        self = Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False)\n        classes = array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819])\n    376 \n    377         n_classes = self.classes_.shape[0]\n    378 \n    379         # Allocate datastructures from input arguments\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\utils\\multiclass.py in _check_partial_fit_first_call(clf=Perceptron(alpha=1.0, class_weight='balanced', e...ffle=True, tol=None, verbose=0, warm_start=False), classes=array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819]))\n    316                     \"`classes=%r` is not the same as on last call \"\n    317                     \"to partial_fit, was: %r\" % (classes, clf.classes_))\n    318 \n    319         else:\n    320             # This is the first call to partial_fit\n--> 321             clf.classes_ = unique_labels(classes)\n        clf.classes_ = undefined\n        classes = array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819])\n    322             return True\n    323 \n    324     # classes is None and clf.classes_ has already previously been set:\n    325     # nothing to do\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\utils\\multiclass.py in unique_labels(*ys=(array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819]),))\n     92                          \"different numbers of labels\")\n     93 \n     94     # Get the unique set of labels\n     95     _unique_labels = _FN_UNIQUE_LABELS.get(label_type, None)\n     96     if not _unique_labels:\n---> 97         raise ValueError(\"Unknown label type: %s\" % repr(ys))\n        ys = (array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819]),)\n     98 \n     99     ys_labels = set(chain.from_iterable(_unique_labels(y) for y in ys))\n    100 \n    101     # Check that we don't mix string type with number type\n\nValueError: Unknown label type: (array([0.        , 0.00057008, 0.02753011, ..., 0.33929943, 0.34458077,\n       0.35229819]),)\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "#from sklearn.linear_model import Perceptron\n",
    "\n",
    "#create regressor\n",
    "#percep = Perceptron()\n",
    "\n",
    "#Create Hyperparamter Search Space\n",
    "#penalty=['l1', 'l2', 'elasticnet']\n",
    "#alpha = [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0]\n",
    "#Create hyperparameter options\n",
    "#percep_param = dict(penalty=penalty, alpha=alpha, n_jobs=n_jobs, class_weight=class_weight)\n",
    "\n",
    "\n",
    "#Apply Grid Search To Determine the best model\n",
    "#s_time = time.time()\n",
    "#best_percep= GridSearch(percep, percep_param, X_train, y_train)\n",
    "#f_time = time.time()\n",
    "#print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#percep.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_percep = rmse_CV(best_percep, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Process Regression\n",
    "\n",
    "> **NOTE:** The optimization failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibLinAlgError",
     "evalue": "JoblibLinAlgError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\runpy.py in _run_code(code=<code object <module> at 0000000002527AB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\Use...s\\py2\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0000000002527AB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\Use...s\\py2\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 3, 27, 1, 56, 17, 869000, tzinfo=tzutc()), u'msg_id': u'447841c7143445a08d1c3654877e0129', u'msg_type': u'execute_request', u'session': u'3f5f6fd3257847f58804872a628c1182', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'447841c7143445a08d1c3654877e0129', 'msg_type': u'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['3f5f6fd3257847f58804872a628c1182']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 3, 27, 1, 56, 17, 869000, tzinfo=tzutc()), u'msg_id': u'447841c7143445a08d1c3654877e0129', u'msg_type': u'execute_request', u'session': u'3f5f6fd3257847f58804872a628c1182', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'447841c7143445a08d1c3654877e0129', 'msg_type': u'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['3f5f6fd3257847f58804872a628c1182'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 3, 27, 1, 56, 17, 869000, tzinfo=tzutc()), u'msg_id': u'447841c7143445a08d1c3654877e0129', u'msg_type': u'execute_request', u'session': u'3f5f6fd3257847f58804872a628c1182', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'447841c7143445a08d1c3654877e0129', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Print object>], cell_name='<ipython-input-13-62b6638ffeb1>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at b86b2b0, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 000000000B37BC30, file \"<ipython-input-13-62b6638ffeb1>\", line 17>\n        result = <ExecutionResult object at b86b2b0, execution_co..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 000000000B37BC30, file \"<ipython-input-13-62b6638ffeb1>\", line 17>, result=<ExecutionResult object at b86b2b0, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 000000000B37BC30, file \"<ipython-input-13-62b6638ffeb1>\", line 17>\n        self.user_global_ns = {'GaussianProcessRegressor': <class 'sklearn.gaussian_process.gpr.GaussianProcessRegressor'>, 'GridSearch': <function GridSearch>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Id': 0          1\n1          2\n2          3\n3        ...1459    1460\nName: Id, Length: 1460, dtype: int64, 'In': ['', u\"# Import libraries necessary for this project\\...books\\nget_ipython().magic(u'matplotlib inline')\", u'#Load the saved file to verify\\ntrain_data = p...s=1, inplace=True)\\n\\ndisplay(train_data.head())', u'#Split TRAINING SET into train and test sets\\n...n\\ndisplay(y_train.shape)\\ndisplay(y_test.shape)', u'from sklearn.model_selection import cross_val_...\\n    print \\'Standard Deviation: \\', rmse.std()', u'from sklearn.metrics import mean_squared_error...   return np.sqrt(mean_squared_error(y, y_pred))', u'from sklearn.gaussian_process import GaussianP...:3f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)', u\"# Import libraries necessary for this project\\...books\\nget_ipython().magic(u'matplotlib inline')\", u'#Load the saved file to verify\\ntrain_data = p...s=1, inplace=True)\\n\\ndisplay(train_data.head())', u'#Split TRAINING SET into train and test sets\\n...n\\ndisplay(y_train.shape)\\ndisplay(y_test.shape)', u'from sklearn.model_selection import cross_val_...\\n    print \\'Standard Deviation: \\', rmse.std()', u'from sklearn.metrics import mean_squared_error...   return np.sqrt(mean_squared_error(y, y_pred))', u'from sklearn.model_selection import GridSearch..._params_)\\n    return best_model.best_estimator_', u'from sklearn.gaussian_process import GaussianP...:3f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)'], 'Out': {}, 'X_test':       MSSubClass   LotArea  OverallQual  Overall...                    0  \n\n[482 rows x 220 columns], 'X_train':       MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], '_': '', '__': '', ...}\n        self.user_ns = {'GaussianProcessRegressor': <class 'sklearn.gaussian_process.gpr.GaussianProcessRegressor'>, 'GridSearch': <function GridSearch>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Id': 0          1\n1          2\n2          3\n3        ...1459    1460\nName: Id, Length: 1460, dtype: int64, 'In': ['', u\"# Import libraries necessary for this project\\...books\\nget_ipython().magic(u'matplotlib inline')\", u'#Load the saved file to verify\\ntrain_data = p...s=1, inplace=True)\\n\\ndisplay(train_data.head())', u'#Split TRAINING SET into train and test sets\\n...n\\ndisplay(y_train.shape)\\ndisplay(y_test.shape)', u'from sklearn.model_selection import cross_val_...\\n    print \\'Standard Deviation: \\', rmse.std()', u'from sklearn.metrics import mean_squared_error...   return np.sqrt(mean_squared_error(y, y_pred))', u'from sklearn.gaussian_process import GaussianP...:3f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)', u\"# Import libraries necessary for this project\\...books\\nget_ipython().magic(u'matplotlib inline')\", u'#Load the saved file to verify\\ntrain_data = p...s=1, inplace=True)\\n\\ndisplay(train_data.head())', u'#Split TRAINING SET into train and test sets\\n...n\\ndisplay(y_train.shape)\\ndisplay(y_test.shape)', u'from sklearn.model_selection import cross_val_...\\n    print \\'Standard Deviation: \\', rmse.std()', u'from sklearn.metrics import mean_squared_error...   return np.sqrt(mean_squared_error(y, y_pred))', u'from sklearn.model_selection import GridSearch..._params_)\\n    return best_model.best_estimator_', u'from sklearn.gaussian_process import GaussianP...:3f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)'], 'Out': {}, 'X_test':       MSSubClass   LotArea  OverallQual  Overall...                    0  \n\n[482 rows x 220 columns], 'X_train':       MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], '_': '', '__': '', ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\User\\Desktop\\Machine Learning ND\\Capstone Project\\Capstone Project\\<ipython-input-13-62b6638ffeb1> in <module>()\n     12 gpr_param = dict(alpha=alpha, optimizer=optimizer)\n     13 \n     14 \n     15 #Apply Grid Search To Determine the best model\n     16 s_time = time.time()\n---> 17 best_gpr= GridSearch(gpr, gpr_param, X_train, y_train)\n     18 f_time = time.time()\n     19 print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n     20 \n     21 #gpr.fit(X,y)\n\n...........................................................................\nC:\\Users\\User\\Desktop\\Machine Learning ND\\Capstone Project\\Capstone Project\\<ipython-input-12-366611827180> in GridSearch(reg=GaussianProcessRegressor(alpha=1e-10, copy_X_tra...    optimizer='fmin_l_bfgs_b', random_state=None), parameters={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0], 'optimizer': ['fmin_l_bfgs_b', None]}, X=      MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], y=615     11.831386\n613     11.898195\n1303    12.3...6816\nName: SalePrice, Length: 978, dtype: float64)\n      1 from sklearn.model_selection import GridSearchCV\n      2 \n      3 def GridSearch(reg, parameters, X, y):\n      4     GSCV = GridSearchCV(reg, parameters, verbose=0, cv=5, n_jobs=-1)\n----> 5     best_model = GSCV.fit(X, y)\n      6     display(best_model)\n      7     display(best_model.best_params_)\n      8     return best_model.best_estimator_\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=      MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], y=615     11.831386\n613     11.898195\n1303    12.3...6816\nName: SalePrice, Length: 978, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method KFold.split of KFold(n_splits=5, random_state=None, shuffle=False)>\n        X =       MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns]\n        y = 615     11.831386\n613     11.898195\n1303    12.3...6816\nName: SalePrice, Length: 978, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nLinAlgError                                        Mon Mar 26 22:56:33 2018\nPID: 6872        Python 2.7.14: C:\\Users\\User\\Anaconda3\\envs\\py2\\python.exe\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GaussianProcessRegressor(alpha=0.0, copy_X_train...    optimizer='fmin_l_bfgs_b', random_state=None),       MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], 615     11.831386\n613     11.898195\n1303    12.3...6816\nName: SalePrice, Length: 978, dtype: float64, {'score': <function _passthrough_scorer>}, array([196, 197, 198, 199, 200, 201, 202, 203, 2..., 970, 971, 972, 973, 974, 975,\n       976, 977]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 188, 189, 190, 191, 192, 193, 194,\n       195]), 0, {'alpha': 0.0, 'optimizer': 'fmin_l_bfgs_b'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (GaussianProcessRegressor(alpha=0.0, copy_X_train...    optimizer='fmin_l_bfgs_b', random_state=None),       MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], 615     11.831386\n613     11.898195\n1303    12.3...6816\nName: SalePrice, Length: 978, dtype: float64, {'score': <function _passthrough_scorer>}, array([196, 197, 198, 199, 200, 201, 202, 203, 2..., 970, 971, 972, 973, 974, 975,\n       976, 977]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 188, 189, 190, 191, 192, 193, 194,\n       195]), 0, {'alpha': 0.0, 'optimizer': 'fmin_l_bfgs_b'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=GaussianProcessRegressor(alpha=0.0, copy_X_train...    optimizer='fmin_l_bfgs_b', random_state=None), X=      MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], y=615     11.831386\n613     11.898195\n1303    12.3...6816\nName: SalePrice, Length: 978, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([196, 197, 198, 199, 200, 201, 202, 203, 2..., 970, 971, 972, 973, 974, 975,\n       976, 977]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 188, 189, 190, 191, 192, 193, 194,\n       195]), verbose=0, parameters={'alpha': 0.0, 'optimizer': 'fmin_l_bfgs_b'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method GaussianProcessRegressor.fit of Ga...   optimizer='fmin_l_bfgs_b', random_state=None)>\n        X_train =       MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[782 rows x 220 columns]\n        y_train = 923     12.170451\n182     11.695255\n987     12.8...6816\nName: SalePrice, Length: 782, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py in fit(self=GaussianProcessRegressor(alpha=0.0, copy_X_train...    optimizer='fmin_l_bfgs_b', random_state=None), X=array([[4.79579055, 8.9888205 , 6.        , ...,....., 0.        , 1.        ,\n        0.        ]]), y=array([12.17045065, 11.69525536, 12.88712953, 11...6, 11.6526961 ,\n       12.15452142, 12.06681633]))\n    242         # Precompute quantities required for predictions which are independent\n    243         # of actual query points\n    244         K = self.kernel_(self.X_train_)\n    245         K[np.diag_indices_from(K)] += self.alpha\n    246         try:\n--> 247             self.L_ = cholesky(K, lower=True)  # Line 2\n        self.L_ = undefined\n        K = array([[1., 0., 0., ..., 0., 0., 0.],\n       [0...., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]])\n    248         except np.linalg.LinAlgError as exc:\n    249             exc.args = (\"The kernel, %s, is not returning a \"\n    250                         \"positive definite matrix. Try gradually \"\n    251                         \"increasing the 'alpha' parameter of your \"\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\scipy\\linalg\\decomp_cholesky.py in cholesky(a=array([[1., 0., 0., ..., 0., 0., 0.],\n       [0...., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]]), lower=True, overwrite_a=False, check_finite=True)\n     86     array([[ 1.+0.j,  0.-2.j],\n     87            [ 0.+2.j,  5.+0.j]])\n     88 \n     89     \"\"\"\n     90     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n---> 91                          check_finite=check_finite)\n        check_finite = True\n     92     return c\n     93 \n     94 \n     95 def cho_factor(a, lower=False, overwrite_a=False, check_finite=True):\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\scipy\\linalg\\decomp_cholesky.py in _cholesky(a=array([[1., 0., 0., ..., 0., 0., 0.],\n       [0...., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]]), lower=True, overwrite_a=False, clean=True, check_finite=True)\n     35     overwrite_a = overwrite_a or _datacopied(a1, a)\n     36     potrf, = get_lapack_funcs(('potrf',), (a1,))\n     37     c, info = potrf(a1, lower=lower, overwrite_a=overwrite_a, clean=clean)\n     38     if info > 0:\n     39         raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n---> 40                           \"definite\" % info)\n        info = 721\n     41     if info < 0:\n     42         raise ValueError('LAPACK reported an illegal value in {}-th argument'\n     43                          'on entry to \"POTRF\".'.format(-info))\n     44     return c, lower\n\nLinAlgError: (\"The kernel, 1**2 * RBF(length_scale=1), is not returning a positive definite matrix. Try gradually increasing the 'alpha' parameter of your GaussianProcessRegressor estimator.\", '721-th leading minor of the array is not positive definite')\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJoblibLinAlgError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-62b6638ffeb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#Apply Grid Search To Determine the best model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0ms_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mbest_gpr\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mGridSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mf_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Training and Fine-Tune Time: {:3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-366611827180>\u001b[0m in \u001b[0;36mGridSearch\u001b[1;34m(reg, parameters, X, y)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mGridSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mGSCV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGSCV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibLinAlgError\u001b[0m: JoblibLinAlgError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\runpy.py in _run_code(code=<code object <module> at 0000000002527AB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\Use...s\\py2\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0000000002527AB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\Users\\Use...s\\py2\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 3, 27, 1, 56, 17, 869000, tzinfo=tzutc()), u'msg_id': u'447841c7143445a08d1c3654877e0129', u'msg_type': u'execute_request', u'session': u'3f5f6fd3257847f58804872a628c1182', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'447841c7143445a08d1c3654877e0129', 'msg_type': u'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['3f5f6fd3257847f58804872a628c1182']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 3, 27, 1, 56, 17, 869000, tzinfo=tzutc()), u'msg_id': u'447841c7143445a08d1c3654877e0129', u'msg_type': u'execute_request', u'session': u'3f5f6fd3257847f58804872a628c1182', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'447841c7143445a08d1c3654877e0129', 'msg_type': u'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['3f5f6fd3257847f58804872a628c1182'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 3, 27, 1, 56, 17, 869000, tzinfo=tzutc()), u'msg_id': u'447841c7143445a08d1c3654877e0129', u'msg_type': u'execute_request', u'session': u'3f5f6fd3257847f58804872a628c1182', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'447841c7143445a08d1c3654877e0129', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'from sklearn.gaussian_process import GaussianP...f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)\\n', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Print object>], cell_name='<ipython-input-13-62b6638ffeb1>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at b86b2b0, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 000000000B37BC30, file \"<ipython-input-13-62b6638ffeb1>\", line 17>\n        result = <ExecutionResult object at b86b2b0, execution_co..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 000000000B37BC30, file \"<ipython-input-13-62b6638ffeb1>\", line 17>, result=<ExecutionResult object at b86b2b0, execution_co..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 000000000B37BC30, file \"<ipython-input-13-62b6638ffeb1>\", line 17>\n        self.user_global_ns = {'GaussianProcessRegressor': <class 'sklearn.gaussian_process.gpr.GaussianProcessRegressor'>, 'GridSearch': <function GridSearch>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Id': 0          1\n1          2\n2          3\n3        ...1459    1460\nName: Id, Length: 1460, dtype: int64, 'In': ['', u\"# Import libraries necessary for this project\\...books\\nget_ipython().magic(u'matplotlib inline')\", u'#Load the saved file to verify\\ntrain_data = p...s=1, inplace=True)\\n\\ndisplay(train_data.head())', u'#Split TRAINING SET into train and test sets\\n...n\\ndisplay(y_train.shape)\\ndisplay(y_test.shape)', u'from sklearn.model_selection import cross_val_...\\n    print \\'Standard Deviation: \\', rmse.std()', u'from sklearn.metrics import mean_squared_error...   return np.sqrt(mean_squared_error(y, y_pred))', u'from sklearn.gaussian_process import GaussianP...:3f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)', u\"# Import libraries necessary for this project\\...books\\nget_ipython().magic(u'matplotlib inline')\", u'#Load the saved file to verify\\ntrain_data = p...s=1, inplace=True)\\n\\ndisplay(train_data.head())', u'#Split TRAINING SET into train and test sets\\n...n\\ndisplay(y_train.shape)\\ndisplay(y_test.shape)', u'from sklearn.model_selection import cross_val_...\\n    print \\'Standard Deviation: \\', rmse.std()', u'from sklearn.metrics import mean_squared_error...   return np.sqrt(mean_squared_error(y, y_pred))', u'from sklearn.model_selection import GridSearch..._params_)\\n    return best_model.best_estimator_', u'from sklearn.gaussian_process import GaussianP...:3f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)'], 'Out': {}, 'X_test':       MSSubClass   LotArea  OverallQual  Overall...                    0  \n\n[482 rows x 220 columns], 'X_train':       MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], '_': '', '__': '', ...}\n        self.user_ns = {'GaussianProcessRegressor': <class 'sklearn.gaussian_process.gpr.GaussianProcessRegressor'>, 'GridSearch': <function GridSearch>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Id': 0          1\n1          2\n2          3\n3        ...1459    1460\nName: Id, Length: 1460, dtype: int64, 'In': ['', u\"# Import libraries necessary for this project\\...books\\nget_ipython().magic(u'matplotlib inline')\", u'#Load the saved file to verify\\ntrain_data = p...s=1, inplace=True)\\n\\ndisplay(train_data.head())', u'#Split TRAINING SET into train and test sets\\n...n\\ndisplay(y_train.shape)\\ndisplay(y_test.shape)', u'from sklearn.model_selection import cross_val_...\\n    print \\'Standard Deviation: \\', rmse.std()', u'from sklearn.metrics import mean_squared_error...   return np.sqrt(mean_squared_error(y, y_pred))', u'from sklearn.gaussian_process import GaussianP...:3f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)', u\"# Import libraries necessary for this project\\...books\\nget_ipython().magic(u'matplotlib inline')\", u'#Load the saved file to verify\\ntrain_data = p...s=1, inplace=True)\\n\\ndisplay(train_data.head())', u'#Split TRAINING SET into train and test sets\\n...n\\ndisplay(y_train.shape)\\ndisplay(y_test.shape)', u'from sklearn.model_selection import cross_val_...\\n    print \\'Standard Deviation: \\', rmse.std()', u'from sklearn.metrics import mean_squared_error...   return np.sqrt(mean_squared_error(y, y_pred))', u'from sklearn.model_selection import GridSearch..._params_)\\n    return best_model.best_estimator_', u'from sklearn.gaussian_process import GaussianP...:3f}\".format((s_time - f_time))\\n\\n#gpr.fit(X,y)'], 'Out': {}, 'X_test':       MSSubClass   LotArea  OverallQual  Overall...                    0  \n\n[482 rows x 220 columns], 'X_train':       MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], '_': '', '__': '', ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\User\\Desktop\\Machine Learning ND\\Capstone Project\\Capstone Project\\<ipython-input-13-62b6638ffeb1> in <module>()\n     12 gpr_param = dict(alpha=alpha, optimizer=optimizer)\n     13 \n     14 \n     15 #Apply Grid Search To Determine the best model\n     16 s_time = time.time()\n---> 17 best_gpr= GridSearch(gpr, gpr_param, X_train, y_train)\n     18 f_time = time.time()\n     19 print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n     20 \n     21 #gpr.fit(X,y)\n\n...........................................................................\nC:\\Users\\User\\Desktop\\Machine Learning ND\\Capstone Project\\Capstone Project\\<ipython-input-12-366611827180> in GridSearch(reg=GaussianProcessRegressor(alpha=1e-10, copy_X_tra...    optimizer='fmin_l_bfgs_b', random_state=None), parameters={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0], 'optimizer': ['fmin_l_bfgs_b', None]}, X=      MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], y=615     11.831386\n613     11.898195\n1303    12.3...6816\nName: SalePrice, Length: 978, dtype: float64)\n      1 from sklearn.model_selection import GridSearchCV\n      2 \n      3 def GridSearch(reg, parameters, X, y):\n      4     GSCV = GridSearchCV(reg, parameters, verbose=0, cv=5, n_jobs=-1)\n----> 5     best_model = GSCV.fit(X, y)\n      6     display(best_model)\n      7     display(best_model.best_params_)\n      8     return best_model.best_estimator_\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=      MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], y=615     11.831386\n613     11.898195\n1303    12.3...6816\nName: SalePrice, Length: 978, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method KFold.split of KFold(n_splits=5, random_state=None, shuffle=False)>\n        X =       MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns]\n        y = 615     11.831386\n613     11.898195\n1303    12.3...6816\nName: SalePrice, Length: 978, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nLinAlgError                                        Mon Mar 26 22:56:33 2018\nPID: 6872        Python 2.7.14: C:\\Users\\User\\Anaconda3\\envs\\py2\\python.exe\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GaussianProcessRegressor(alpha=0.0, copy_X_train...    optimizer='fmin_l_bfgs_b', random_state=None),       MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], 615     11.831386\n613     11.898195\n1303    12.3...6816\nName: SalePrice, Length: 978, dtype: float64, {'score': <function _passthrough_scorer>}, array([196, 197, 198, 199, 200, 201, 202, 203, 2..., 970, 971, 972, 973, 974, 975,\n       976, 977]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 188, 189, 190, 191, 192, 193, 194,\n       195]), 0, {'alpha': 0.0, 'optimizer': 'fmin_l_bfgs_b'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (GaussianProcessRegressor(alpha=0.0, copy_X_train...    optimizer='fmin_l_bfgs_b', random_state=None),       MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], 615     11.831386\n613     11.898195\n1303    12.3...6816\nName: SalePrice, Length: 978, dtype: float64, {'score': <function _passthrough_scorer>}, array([196, 197, 198, 199, 200, 201, 202, 203, 2..., 970, 971, 972, 973, 974, 975,\n       976, 977]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 188, 189, 190, 191, 192, 193, 194,\n       195]), 0, {'alpha': 0.0, 'optimizer': 'fmin_l_bfgs_b'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=GaussianProcessRegressor(alpha=0.0, copy_X_train...    optimizer='fmin_l_bfgs_b', random_state=None), X=      MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[978 rows x 220 columns], y=615     11.831386\n613     11.898195\n1303    12.3...6816\nName: SalePrice, Length: 978, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([196, 197, 198, 199, 200, 201, 202, 203, 2..., 970, 971, 972, 973, 974, 975,\n       976, 977]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 188, 189, 190, 191, 192, 193, 194,\n       195]), verbose=0, parameters={'alpha': 0.0, 'optimizer': 'fmin_l_bfgs_b'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method GaussianProcessRegressor.fit of Ga...   optimizer='fmin_l_bfgs_b', random_state=None)>\n        X_train =       MSSubClass    LotArea  OverallQual  Overal...                    0  \n\n[782 rows x 220 columns]\n        y_train = 923     12.170451\n182     11.695255\n987     12.8...6816\nName: SalePrice, Length: 782, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py in fit(self=GaussianProcessRegressor(alpha=0.0, copy_X_train...    optimizer='fmin_l_bfgs_b', random_state=None), X=array([[4.79579055, 8.9888205 , 6.        , ...,....., 0.        , 1.        ,\n        0.        ]]), y=array([12.17045065, 11.69525536, 12.88712953, 11...6, 11.6526961 ,\n       12.15452142, 12.06681633]))\n    242         # Precompute quantities required for predictions which are independent\n    243         # of actual query points\n    244         K = self.kernel_(self.X_train_)\n    245         K[np.diag_indices_from(K)] += self.alpha\n    246         try:\n--> 247             self.L_ = cholesky(K, lower=True)  # Line 2\n        self.L_ = undefined\n        K = array([[1., 0., 0., ..., 0., 0., 0.],\n       [0...., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]])\n    248         except np.linalg.LinAlgError as exc:\n    249             exc.args = (\"The kernel, %s, is not returning a \"\n    250                         \"positive definite matrix. Try gradually \"\n    251                         \"increasing the 'alpha' parameter of your \"\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\scipy\\linalg\\decomp_cholesky.py in cholesky(a=array([[1., 0., 0., ..., 0., 0., 0.],\n       [0...., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]]), lower=True, overwrite_a=False, check_finite=True)\n     86     array([[ 1.+0.j,  0.-2.j],\n     87            [ 0.+2.j,  5.+0.j]])\n     88 \n     89     \"\"\"\n     90     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n---> 91                          check_finite=check_finite)\n        check_finite = True\n     92     return c\n     93 \n     94 \n     95 def cho_factor(a, lower=False, overwrite_a=False, check_finite=True):\n\n...........................................................................\nC:\\Users\\User\\Anaconda3\\envs\\py2\\lib\\site-packages\\scipy\\linalg\\decomp_cholesky.py in _cholesky(a=array([[1., 0., 0., ..., 0., 0., 0.],\n       [0...., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]]), lower=True, overwrite_a=False, clean=True, check_finite=True)\n     35     overwrite_a = overwrite_a or _datacopied(a1, a)\n     36     potrf, = get_lapack_funcs(('potrf',), (a1,))\n     37     c, info = potrf(a1, lower=lower, overwrite_a=overwrite_a, clean=clean)\n     38     if info > 0:\n     39         raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n---> 40                           \"definite\" % info)\n        info = 721\n     41     if info < 0:\n     42         raise ValueError('LAPACK reported an illegal value in {}-th argument'\n     43                          'on entry to \"POTRF\".'.format(-info))\n     44     return c, lower\n\nLinAlgError: (\"The kernel, 1**2 * RBF(length_scale=1), is not returning a positive definite matrix. Try gradually increasing the 'alpha' parameter of your GaussianProcessRegressor estimator.\", '721-th leading minor of the array is not positive definite')\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "#from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "#Create Regressor\n",
    "#gpr = GaussianProcessRegressor()\n",
    "\n",
    "#Create Hyperparamter Search Space\n",
    "#kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "#alpha = [1.0, 0.1, 0.01, 0.001, 0.0001, 0.0]\n",
    "#optimizer = ['fmin_l_bfgs_b', None]\n",
    "\n",
    "#Create hyperparameter options\n",
    "#gpr_param = dict(alpha=alpha, optimizer=optimizer)\n",
    "\n",
    "\n",
    "#Apply Grid Search To Determine the best model\n",
    "#s_time = time.time()\n",
    "#best_gpr= GridSearch(gpr, gpr_param, X_train, y_train)\n",
    "#f_time = time.time()\n",
    "#print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n",
    "\n",
    "#gpr.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_gpr = rmse_CV(best_gpr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': ['auto', 'sqrt', 'log2', None], 'alpha': [0.9, 0.5, 0.1, 0.05, 0.01, 0.001, 0.0001], 'criterion': ['mse'], 'max_depth': [2, 4, 6, 8, 10, 12], 'loss': ['ls', 'lad', 'huber', 'quantile']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001,\n",
       " 'criterion': 'mse',\n",
       " 'loss': 'ls',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'sqrt'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Fine-Tune Time: -1492.864000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#Create Regressor\n",
    "GBR = GradientBoostingRegressor()\n",
    "\n",
    "#Create Hyperparamter Search Space\n",
    "loss = ['ls', 'lad', 'huber', 'quantile']\n",
    "criterion = ['mse']\n",
    "alpha = [0.9, 0.5, 0.1, 0.05, 0.01, 0.001, 0.0001]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "max_depth = [2, 4, 6, 8, 10, 12]\n",
    "\n",
    "#Create hyperparameter options\n",
    "GBR_param = dict(loss=loss,criterion=criterion, alpha=alpha, max_features=max_features, max_depth=max_depth)\n",
    "\n",
    "#Apply Grid Search To Determine the best model\n",
    "s_time = time.time()\n",
    "best_GBR= GridSearch(GBR, GBR_param, X_train, y_train)\n",
    "f_time = time.time()\n",
    "print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.13831081 0.15751812 0.13147632]\n",
      "Mean: 0.1424350829195781\n",
      "Standard Deviation:  0.011024247065513146\n"
     ]
    }
   ],
   "source": [
    "score_GBR = rmse_CV(best_GBR, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': ['auto', 'sqrt', 'log2', None], 'n_jobs': [-1], 'criterion': ['mse'], 'max_depth': [2, 4, 6, 8, 10, 12]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse', 'max_depth': 10, 'max_features': None, 'n_jobs': -1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Fine-Tune Time: -17.057000\n"
     ]
    }
   ],
   "source": [
    "#Random Forest regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Create Regressor\n",
    "rand_F = RandomForestRegressor()\n",
    "\n",
    "#Create Hyperparamter Search Space\n",
    "criterion = ['mse']\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "max_depth = [2, 4, 6, 8, 10, 12]\n",
    "n_jobs=[-1]\n",
    "\n",
    "#Create hyperparameter options\n",
    "rand_param = dict(criterion=criterion, max_features=max_features, max_depth=max_depth, n_jobs=n_jobs)\n",
    "\n",
    "#Apply Grid Search To Determine the best model\n",
    "s_time = time.time()\n",
    "best_rand_F= GridSearch(rand_F, rand_param, X_train, y_train)\n",
    "f_time = time.time()\n",
    "print \"Training and Fine-Tune Time: {:3f}\".format((s_time - f_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Metric\n",
      "Scores:  [0.17184903 0.18673306 0.15451401]\n",
      "Mean: 0.17103203417143517\n",
      "Standard Deviation:  0.013166050755315364\n"
     ]
    }
   ],
   "source": [
    "score_rand = rmse_CV(best_rand_F, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
